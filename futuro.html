<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Visión a Futuro</title>
	<link rel="stylesheet" type="text/css" href="futuro.css">
</head>
<body>
	<header>
	<nav>
		<a href="BigData.html" class="nav-link">Inicio</a>
		<a href="Historia.html" class="nav-link">Historia</a>
		<a href="Objetivo.html" class="nav-link">Objetivo</a>
		<a href="actual.html" class="nav-link">¿Qué se espera?</a>
		<a href="futuro.html" class="nav-link">Visión a Futuro</a>
		<a href="Imagenes.html" class="nav-link">Imagenes</a>
		<a href="beneficios" class="nav-link">Beneficios</a>
		<a href="fucion" class="nav-link">Como funciona</a>
	</nav>
</header>
	<h1>Visión a Futuro</h1>
	<div id="t1">
		<h1>1. El volumen de datos no hará si aumentan<br>Los expertos en big data afirman que el volumen de datos producidos crecerá exponencialmente. Según el informe Data Age 2025 de IDC, para el año 2025, la cantidad de datos podría alcanzar los 175 zettabytes. Eso es 40 veces más que el volumen de datos de 2013.</h1>
	</div><br>
	<div id="t1">
		<h1>2. El aprendizaje automático seguirá desarrollándose<br>Como dijo Wei Li, Vicepresidente y Director General de Intel, cada año el aprendizaje automático se vuelve más y más sofisticado. Lo utilizamos en coches autoconducidos, dispositivos de detección de fraudes y big data, y el número de formas en que lo utilizamos no hará más que crecer. Esto se debe a que el aprendizaje automático depende de la cantidad de datos de entrada, de modo que a medida que aumenta la cantidad de datos, también lo hace la precisión de los resultados del aprendizaje automático.<br>Además, durante mucho tiempo el aprendizaje automático no estuvo al alcance de la mayoría de las empresas porque las plataformas de código abierto dominaban este ámbito. Esto significa que las empresas que querían implementar el aprendizaje automático en sus procesos tenían que configurar las soluciones por su cuenta, y la mayoría de ellas adolecían de falta de conocimientos en este ámbito. Pero todo cambió cuando los proveedores comerciales empezaron a crear sus propias soluciones asequibles que no requieren demasiada configuración. Las aplicaciones y plataformas de aprendizaje automático han reunido 28.500 y 14.400 millones de dólares estadounidenses respectivamente en financiación hasta marzo de 2019, y estas cifras aumentan a medida que lo hace la demanda.
</h1>
	</div><br>
	<div id="t1">
		<h1>3. Los expertos en big data estarán muy solicitados<br>Puestos como el de director de datos y científico de datos son relativamente nuevos y sólo existen realmente desde la implantación masiva de machine learning y big data.<br>Un buen responsable o científico de datos también es valioso por su base de conocimientos. Tienen que estar familiarizados con una amplia gama de temas, como lenguajes de programación, algoritmos de aprendizaje automático, técnicas de manipulación de datos y plataformas y herramientas de datos. Los especialistas tienen que conocer las últimas tendencias y cómo utilizarlas para resolver tareas concretas, lo que requiere tiempo y experiencia. Aunque estos dos factores implican que los especialistas pueden ser caros, potencialmente pueden aportar importantes beneficios a su empresa, por lo que empezar a buscar un especialista ahora puede ser una buena idea.
</h1>
	</div><br>
	<div id="t1">
		<h1>4. El uso de datos rápidos y procesables aumentará rápidamente<br>La competencia entre empresas significa que tienen que tomar decisiones que cambien el juego antes incluso de que otros competidores vean la oportunidad. Big data facilita la búsqueda de estos cambios y la actuación en consecuencia.<br>Si hablamos de análisis de datos, incluso cuando se trata de aprendizaje automático, solemos referirnos al análisis en modo batch (cuando recopilamos lotes de datos, se los damos a un algoritmo y éste nos da información valiosa sobre la salida). Pero esto no significa que podamos tomar una decisión en el momento en que obtenemos los datos; se necesita tiempo para hacer un análisis final.<br>Los datos rápidos permiten procesarlos en tiempo real, tal y como aparecen en nuestras bases de datos. Eso significa que podemos analizar los cambios en los flujos de datos sobre la marcha y responder a ellos rápidamente. Es un auténtico cambio de juego.<br>Los datos procesables son el resultado del análisis de big data. Cuando se obtiene un gran número de datos de diversos tipos, apenas se puede hacer nada con ellos. Pero tras procesarlos con herramientas de análisis de big data, podemos obtener información que nos ayudará a tomar decisiones informadas y racionales.<br>Según algunos expertos, en el futuro los big data podrían incluso ser sustituidos por datos rápidos y datos procesables.</h1>
	</div><br>
	<div id="t1">
		<h1>5. Más empresas intentarán monetizar sus datos<br>Los datos se recogen en todas partes, desde tiendas de comestibles hasta sitios web y aplicaciones, y todos estos datos pueden venderse a otras empresas como otra fuente de ingresos. La demanda de este tipo de datos es alta y no parece que vaya a disminuir.</h1>
	</div><br>
	<div id="t1">
		<h1>6. Más herramientas de data analysis ya no requerirán un analista<br>La demanda de data analysis es alta, pero como ya hemos dicho, faltan profesionales en este campo. Es muy posible que los proveedores empiecen a ofrecer a los clientes soluciones que requieran muchos menos conocimientos técnicos</h1>
	</div><br>
	<div id="t1">
		<h1>7. Big data podría acabar con el debate sobre el cambio climático<br>Otros big data analysis puede ayudar a los científicos a comprender mejor el cambio climático y sus causas y efectos. Esto contribuirá a que los debates políticos se basen en pruebas.</h1>
	</div><br>
	<div id="t1">
		<h1>8. Big data podría ayudar a curar enfermedades infecciosas<br>La sanidad es uno de los principales sectores usuarios de big data. Algunos científicos creen que, tras consolidar grandes cantidades de historiales médicos en un lote de datos, podrían encontrarse nuevas curas mucho antes de lo esperado.<br>Tienen puntos, pero esta idea se enfrenta a dos grandes problemas. En primer lugar, el volumen de datos de historias clínicas rondaba los 170 exabytes solo en 2019, y el aumento anual estimado es de 1,2 a 2,4 exabytes al año. Eso es una gran cantidad de datos, y el desafío es reunirlos y almacenarlos en un solo lugar. Otro reto es que las instituciones de investigación pueden ralentizar el proceso de descubrimiento a través de la complicada ley de patentes.</h1>
	</div><br>
	<div id="t1">
		<h1>9. El procesamiento del lenguaje natural (PLN) se utilizará más ampliamente<br>La tecnología se vuelve más asequible y fácil de usar a medida que se desarrolla. Algunos expertos predicen que en un futuro próximo no tendremos que utilizar código para interactuar con sistemas inteligentes.<br>Las empresas pueden beneficiarse de la PNL incluso ahora, proporcionando a sus clientes chatbots inteligentes que pueden proporcionar información rápidamente, como lo haría un agente humano. El análisis de las interacciones verbales entre el cliente y la empresa también puede ayudar a los profesionales del marketing a comprender cómo se siente el cliente respecto a la marca.</h1>
	</div><br>
	<div id="t1">
		<h1>10. La ciberseguridad seguirá siendo un reto<br>Cuantos más datos se almacenen, más difícil será protegerlos. Las empresas que utilizan big data se enfrentarán a más retos de ciberseguridad, ya que el uso de productos de software adicionales conlleva más oportunidades para que los ciberdelincuentes roben datos.
</h1>
	</div><br>
	<div id="t1">
		<h1>11. Los datos seguirán migrando a la nube<br>Dado que el volumen de datos es cada vez mayor, las empresas que los utilizan tendrán que elegir entre establecer un almacenamiento de datos con más capacidad o dejar que los servicios en la nube se encarguen del problema del almacenamiento de datos. Teniendo en cuenta el hecho de que los servicios en la nube ofrecen un gran espacio de almacenamiento a precios asequibles sin necesidad de mantenimiento de hardware, esperamos que la mayoría opte por lo segundo. Esto es especialmente cierto porque si te quedas sin espacio de almacenamiento en la nube, no tienes que instalar aún más hardware; sólo tienes que ampliar tu plan.
</h1>
	</div><br>
	<div id="t1">
		<h1>12. Big data no sustituirá a los investigadores<br>Es obvio que el análisis de big data puede dar mucha más información que los métodos de investigación tradicionales, y esta información será más precisa y valiosa. Pero el principal problema es que podemos enseñar a una máquina a encontrar patrones y correlaciones, pero no podemos enseñarle a entender el contexto tan bien como un humano. Así que los expertos en big data seguirán siendo una ayuda para los investigadores, no un sustituto.
</h1>
	</div><br>
	<div id="t1">
		<h1>13. En el futuro, las habilidades de ciencia de datos podrían llegar a ser tan comunes como lo son hoy las habilidades de uso de Excel<br>El consejero delegado y fundador de Lotame, Andy Monfried, presume que surgirán aplicaciones de big data de autoservicio con una interfaz fácil de usar, lo que hará que casi todos los trabajadores sean capaces de analizar grandes volúmenes de datos, lo que podría convertirse en una rutina laboral en el futuro.
</h1>
	</div><br>
	<div id="t1">
		<h1>14. El Big Data se integrará con el Internet de las Cosas (IoT)<br>Las empresas buscan constantemente obtener más beneficios de sus productos, y la generación de datos es una forma de conseguirlo. Es probable que los dispositivos IoT recopilen mucha información sobre los usuarios y su entorno. A continuación, estos datos pueden analizarse dentro de la empresa para mejorar la experiencia del cliente o venderse.
</h1>
	</div><br>
	<div id="t1">
		<h1>15. Se analizarán más datos y se utilizarán en la toma de decisiones<br>El 99,5% de los datos recopilados nunca se analiza ni se utiliza de ninguna manera. Esto supone una enorme pérdida para las empresas que recopilan esos datos. Con el desarrollo de big data y machine learning, este porcentaje se reducirá definitivamente. Los científicos de datos encontrarán sin duda una forma de utilizar ese 99,5%.
</h1>
	</div><br>
	<div id="t1">
		<h1>16. Las empresas que utilicen big data tendrán menos gastos<br>Según las encuestas realizadas por Syncsort y NewVantage, el análisis de Big Data ayudó al 59,4% de los encuestados a reducir gastos. El 66,7% de las empresas empezaron a utilizar big data específicamente con ese fin.
</h1>
	</div><br>
	<div id="t1">
		<h1>17. El big data renovará el interés por la tecnología blockchain<br>Las grandes cantidades de datos plantean problemas de seguridad, y la cadena de bloques puede ser muy útil para resolverlos. Es posible que en un futuro próximo veamos un mayor interés por la tecnología blockchain para la seguridad de los datos.
</h1>
	</div><br>
	<div id="t1">
		<h1>18. Las empresas empezarán a utilizar más de una herramienta de análisis de datos<br>Las herramientas de análisis de datos siguen siendo nuevas y, a veces, un producto de software no puede satisfacer todas las necesidades de una empresa concreta. Por ejemplo, una solución puede ser bastante buena para trabajar con big data, pero no tener capacidades de análisis rápido de datos, mientras que otra puede ser capaz de hacer datos rápidos pero tener una interfaz de usuario poco amigable.<br>Por eso las empresas combinarán distintas aplicaciones para generar el máximo beneficio. Según Gartner, algunas empresas ya utilizan más de una aplicación "estándar empresarial".
</h1>
	</div><br>
	<div id="t1">
		<h1>19. Se espera un mayor uso de la arquitectura de tejido de datos<br>Data Fabric es una arquitectura que soporta datos y análisis componibles junto con una variedad de sus componentes. Entre sus ventajas se incluyen una reducción de 30% en el tiempo de diseño de la integración, una reducción de 30% en el tiempo de despliegue y una reducción de 70% en el mantenimiento. Data Fabric también puede aprovechar las capacidades y tecnologías existentes de los concentradores de datos, los lagos de datos y los almacenes de datos. Todo esto, junto con la capacidad de introducir nuevos enfoques y herramientas para el futuro, no deja casi ninguna duda de que esta arquitectura se utilizará ampliamente.
</h1>
	</div><br>
	<div id="t1">
		<h1>20. El GDPR seguirá siendo una gran preocupación<br>Las iniciativas de gobernanza de datos no han reducido sus actividades. El GDPR ha designado a los clientes como firmes propietarios de cualquier información que creen, y tienen el poder de elegir a qué empresas quieren ceder sus datos. Si una empresa se comporta mal, pueden irse a un competidor, con la consiguiente pérdida de ingresos.<br>El big data depende de los clientes, por lo que las empresas tendrán que cumplir el GDPR y las normativas locales, no solo para evitar sanciones, sino también para mantener sus ingresos de datos.
</h1>
	</div><br>
</body>
</html>
